{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd83f910",
   "metadata": {},
   "source": [
    "# 1. Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "10f96a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f991cd6",
   "metadata": {},
   "source": [
    "# 2. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7706987b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('push_up_hand_position_fix.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "882d357b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah data kelas 0: 2674\n",
      "Jumlah data kelas 1: 3319\n"
     ]
    }
   ],
   "source": [
    "jumlah_kelas_0 = df[df['class'] == 0].shape[0]\n",
    "jumlah_kelas_1 = df[df['class'] == 1].shape[0]\n",
    "\n",
    "print(\"Jumlah data kelas 0:\", jumlah_kelas_0)\n",
    "print(\"Jumlah data kelas 1:\", jumlah_kelas_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "078c3c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('class', axis=1)\n",
    "y = df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1281c831",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "X, y = smote.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ecda0e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d8248ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494b46a9",
   "metadata": {},
   "source": [
    "# 3. Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a3254876",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    layers.Dense(64, input_dim=132, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    layers.Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    layers.Dense(1, activation='sigmoid')  \n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "529b05ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "898072f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AccuracyStopCallback(Callback):\n",
    "    def __init__(self, target_accuracy=0.99):\n",
    "        super(AccuracyStopCallback, self).__init__()\n",
    "        self.target_accuracy = target_accuracy\n",
    "        self.val_accuracy = target_accuracy\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if logs.get('accuracy') >= self.target_accuracy and logs.get('val_accuracy') >= self.target_accuracy:\n",
    "            print(f\"\\nReached target accuracy of {self.target_accuracy}, stopping training!\")\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2d33ef20",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = AccuracyStopCallback(target_accuracy=0.97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f75653f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "161/166 [============================>.] - ETA: 0s - loss: 0.9503 - accuracy: 0.9740\n",
      "Reached target accuracy of 0.97, stopping training!\n",
      "166/166 [==============================] - 2s 11ms/step - loss: 0.9362 - accuracy: 0.9748 - val_loss: 0.5429 - val_accuracy: 0.9940\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22d3bdec490>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=20, batch_size=32, validation_split=0.2, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b161d73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ASUS\\AppData\\Local\\Temp\\tmpbjgp51o2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ASUS\\AppData\\Local\\Temp\\tmpbjgp51o2\\assets\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open('model_head_position.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f08b58",
   "metadata": {},
   "source": [
    "# 4. Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "19025ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: 0.6369575262069702\n",
      "Result: 0.6364229321479797\n",
      "Result: 0.6393422484397888\n",
      "Result: 0.6375902891159058\n",
      "Result: 0.6323860287666321\n",
      "Result: 0.6324885487556458\n",
      "Result: 0.6340835094451904\n",
      "Result: 0.6394277215003967\n",
      "Result: 0.6523882746696472\n",
      "Result: 0.6544374227523804\n",
      "Result: 0.6510941982269287\n",
      "Result: 0.6403170228004456\n",
      "Result: 0.6389591097831726\n",
      "Result: 0.6409387588500977\n",
      "Result: 0.6395072937011719\n",
      "Result: 0.6334919929504395\n",
      "Result: 0.6263447403907776\n",
      "Result: 0.6190959811210632\n",
      "Result: 0.5975582599639893\n",
      "Result: 0.5745760798454285\n",
      "Result: 0.5730619430541992\n",
      "Result: 0.5602943301200867\n",
      "Result: 0.5499590039253235\n",
      "Result: 0.5400972962379456\n",
      "Result: 0.5286163687705994\n",
      "Result: 0.5275354981422424\n",
      "Result: 0.5086233615875244\n",
      "Result: 0.5106104612350464\n",
      "Result: 0.5007687211036682\n",
      "Result: 0.49781128764152527\n",
      "Result: 0.5011120438575745\n",
      "Result: 0.5001294016838074\n",
      "Result: 0.501552402973175\n",
      "Result: 0.4965318739414215\n",
      "Result: 0.49892622232437134\n",
      "Result: 0.49439501762390137\n",
      "Result: 0.49056777358055115\n",
      "Result: 0.49182531237602234\n",
      "Result: 0.4875625967979431\n",
      "Result: 0.4869423806667328\n",
      "Result: 0.48683449625968933\n",
      "Result: 0.48717013001441956\n",
      "Result: 0.4887678921222687\n",
      "Result: 0.48516255617141724\n",
      "Result: 0.48710450530052185\n",
      "Result: 0.48713862895965576\n",
      "Result: 0.48663780093193054\n",
      "Result: 0.4964647591114044\n",
      "Result: 0.5051991939544678\n",
      "Result: 0.5139327645301819\n",
      "Result: 0.5199495553970337\n",
      "Result: 0.5226371884346008\n",
      "Result: 0.5374758839607239\n",
      "Result: 0.5664291381835938\n",
      "Result: 0.5832051038742065\n",
      "Result: 0.5882263779640198\n",
      "Result: 0.5988309383392334\n",
      "Result: 0.6052268147468567\n",
      "Result: 0.6064201593399048\n",
      "Result: 0.6247116923332214\n",
      "Result: 0.6252130270004272\n",
      "Result: 0.6459894776344299\n",
      "Result: 0.6475988626480103\n",
      "Result: 0.6567115783691406\n",
      "Result: 0.6497315168380737\n",
      "Result: 0.6568883657455444\n",
      "Result: 0.666525661945343\n",
      "Result: 0.6690142750740051\n",
      "Result: 0.679306149482727\n",
      "Result: 0.6786274909973145\n",
      "Result: 0.6776779890060425\n",
      "Result: 0.6813335418701172\n",
      "Result: 0.6836910843849182\n",
      "Result: 0.6823891997337341\n",
      "Result: 0.6792247891426086\n",
      "Result: 0.6814790964126587\n",
      "Result: 0.6812060475349426\n",
      "Result: 0.6841726303100586\n",
      "Result: 0.6845539808273315\n",
      "Result: 0.6855632662773132\n",
      "Result: 0.6853981018066406\n",
      "Result: 0.6864267587661743\n",
      "Result: 0.6861381530761719\n",
      "Result: 0.6854027509689331\n",
      "Result: 0.6847659945487976\n",
      "Result: 0.6856492161750793\n",
      "Result: 0.6873070597648621\n",
      "Result: 0.6855820417404175\n",
      "Result: 0.6812120079994202\n",
      "Result: 0.6798033714294434\n",
      "Result: 0.6788959503173828\n",
      "Result: 0.6810328364372253\n",
      "Result: 0.6770843863487244\n",
      "Result: 0.6709067821502686\n",
      "Result: 0.6609160304069519\n",
      "Result: 0.6560950875282288\n",
      "Result: 0.6462035775184631\n",
      "Result: 0.6457375884056091\n",
      "Result: 0.6352820992469788\n",
      "Result: 0.6280491948127747\n",
      "Result: 0.6272530555725098\n",
      "Result: 0.6208909749984741\n",
      "Result: 0.619558572769165\n",
      "Result: 0.6018235087394714\n",
      "Result: 0.5822358131408691\n",
      "Result: 0.5798376202583313\n",
      "Result: 0.5708761811256409\n",
      "Result: 0.5603955388069153\n",
      "Result: 0.5466622114181519\n",
      "Result: 0.535712718963623\n",
      "Result: 0.5381093621253967\n",
      "Result: 0.5209251642227173\n",
      "Result: 0.5074147582054138\n",
      "Result: 0.5113798975944519\n",
      "Result: 0.503130316734314\n",
      "Result: 0.5029674172401428\n",
      "Result: 0.49897339940071106\n",
      "Result: 0.4915941655635834\n",
      "Result: 0.4858730435371399\n",
      "Result: 0.49277248978614807\n",
      "Result: 0.4949900209903717\n",
      "Result: 0.49177801609039307\n",
      "Result: 0.4915609657764435\n",
      "Result: 0.4934875965118408\n",
      "Result: 0.4910755753517151\n",
      "Result: 0.4883827269077301\n",
      "Result: 0.4907129406929016\n",
      "Result: 0.48853054642677307\n",
      "Result: 0.4909062385559082\n",
      "Result: 0.502936601638794\n",
      "Result: 0.5085745453834534\n",
      "Result: 0.524394690990448\n",
      "Result: 0.541320264339447\n",
      "Result: 0.5578886866569519\n",
      "Result: 0.5823882818222046\n",
      "Result: 0.5887689590454102\n",
      "Result: 0.6062402129173279\n",
      "Result: 0.6115227341651917\n",
      "Result: 0.6271934509277344\n",
      "Result: 0.6345989108085632\n",
      "Result: 0.6335098147392273\n",
      "Result: 0.6382715106010437\n",
      "Result: 0.6510359048843384\n",
      "Result: 0.6538068056106567\n",
      "Result: 0.6491310596466064\n",
      "Result: 0.6628197431564331\n",
      "Result: 0.6685317754745483\n",
      "Result: 0.6720156073570251\n",
      "Result: 0.6743690371513367\n",
      "Result: 0.6758140325546265\n",
      "Result: 0.666354775428772\n",
      "Result: 0.6537578701972961\n",
      "Result: 0.6443572044372559\n",
      "Result: 0.6297519207000732\n",
      "Result: 0.6303019523620605\n",
      "Result: 0.630400538444519\n",
      "Result: 0.6331305503845215\n",
      "Result: 0.6341302394866943\n",
      "Result: 0.6321394443511963\n",
      "Result: 0.6276911497116089\n",
      "Result: 0.627773106098175\n",
      "Result: 0.6309454441070557\n",
      "Result: 0.6259938478469849\n",
      "Result: 0.6235190629959106\n",
      "Result: 0.6265783309936523\n",
      "Result: 0.629376232624054\n",
      "Result: 0.6302701830863953\n",
      "Result: 0.629675567150116\n",
      "Result: 0.6298814415931702\n",
      "Result: 0.6338745355606079\n",
      "Result: 0.6354010701179504\n",
      "Result: 0.6367922425270081\n",
      "Result: 0.6383678317070007\n",
      "Result: 0.640127956867218\n",
      "Result: 0.639859139919281\n",
      "Result: 0.6400542259216309\n",
      "Result: 0.6401402354240417\n",
      "Result: 0.6413628458976746\n",
      "Result: 0.6412180066108704\n",
      "Result: 0.6395223140716553\n",
      "Result: 0.6378417015075684\n",
      "Result: 0.6376811861991882\n",
      "Result: 0.6385873556137085\n",
      "Result: 0.6408543586730957\n",
      "Result: 0.640605092048645\n",
      "Result: 0.6408649682998657\n",
      "Result: 0.6409399509429932\n",
      "Result: 0.6425877809524536\n",
      "Result: 0.6465629935264587\n",
      "Result: 0.6434235572814941\n",
      "Result: 0.6467062830924988\n",
      "Result: 0.6532419323921204\n",
      "Result: 0.6599773168563843\n",
      "Result: 0.6622416377067566\n",
      "Result: 0.6612223386764526\n",
      "Result: 0.6712898015975952\n",
      "Result: 0.6725614666938782\n",
      "Result: 0.6771293878555298\n",
      "Result: 0.6840199828147888\n",
      "Result: 0.685703694820404\n",
      "Result: 0.6883035898208618\n",
      "Result: 0.6913241744041443\n",
      "Result: 0.6943780779838562\n",
      "Result: 0.6899824142456055\n",
      "Result: 0.686785876750946\n",
      "Result: 0.6800475120544434\n",
      "Result: 0.6789811253547668\n",
      "Result: 0.6757651567459106\n",
      "Result: 0.6792206168174744\n",
      "Result: 0.6833979487419128\n",
      "Result: 0.6774060130119324\n",
      "Result: 0.6663081049919128\n",
      "Result: 0.6469333171844482\n",
      "Result: 0.6440374255180359\n",
      "Result: 0.6301130652427673\n",
      "Result: 0.6218060851097107\n",
      "Result: 0.6178188323974609\n",
      "Result: 0.6124430298805237\n",
      "Result: 0.6157631874084473\n",
      "Result: 0.6148658990859985\n",
      "Result: 0.6150501370429993\n",
      "Result: 0.6177700161933899\n",
      "Result: 0.6183738708496094\n",
      "Result: 0.6221677660942078\n",
      "Result: 0.6215723752975464\n",
      "Result: 0.6207483410835266\n",
      "Result: 0.61505526304245\n",
      "Result: 0.6113039255142212\n",
      "Result: 0.61173015832901\n",
      "Result: 0.6113126277923584\n",
      "Result: 0.6116456985473633\n",
      "Result: 0.6121855974197388\n",
      "Result: 0.6157156229019165\n",
      "Result: 0.6156280636787415\n",
      "Result: 0.6190860271453857\n",
      "Result: 0.6115738749504089\n",
      "Result: 0.6122133731842041\n",
      "Result: 0.6129158735275269\n",
      "Result: 0.6240948438644409\n",
      "Result: 0.6257186532020569\n",
      "Result: 0.6304745078086853\n",
      "Result: 0.6455641984939575\n",
      "Result: 0.6491715908050537\n",
      "Result: 0.6567351222038269\n",
      "Result: 0.6602327227592468\n",
      "Result: 0.6591898798942566\n",
      "Result: 0.6558109521865845\n",
      "Result: 0.6506050825119019\n",
      "Result: 0.6527850031852722\n",
      "Result: 0.649867594242096\n",
      "Result: 0.6567921042442322\n",
      "Result: 0.6669294834136963\n",
      "Result: 0.6693158149719238\n",
      "Result: 0.6580109000205994\n",
      "Result: 0.6514303684234619\n",
      "Result: 0.6428377628326416\n",
      "Result: 0.6392371654510498\n",
      "Result: 0.6299535632133484\n",
      "Result: 0.6168548464775085\n",
      "Result: 0.6185145378112793\n",
      "Result: 0.6028690338134766\n",
      "Result: 0.5780422687530518\n",
      "Result: 0.5650908946990967\n",
      "Result: 0.5529255867004395\n",
      "Result: 0.5557291507720947\n",
      "Result: 0.5522707104682922\n",
      "Result: 0.5112079381942749\n",
      "Result: 0.5173683166503906\n",
      "Result: 0.5067139267921448\n",
      "Result: 0.5054922699928284\n",
      "Result: 0.506740391254425\n",
      "Result: 0.49579158425331116\n",
      "Result: 0.4899043142795563\n",
      "Result: 0.48619696497917175\n",
      "Result: 0.4841035306453705\n",
      "Result: 0.48380669951438904\n",
      "Result: 0.47895416617393494\n",
      "Result: 0.4842545688152313\n",
      "Result: 0.49799618124961853\n",
      "Result: 0.5027152895927429\n",
      "Result: 0.5165374279022217\n",
      "Result: 0.5396155118942261\n",
      "Result: 0.558755099773407\n",
      "Result: 0.584828794002533\n",
      "Result: 0.5901265144348145\n",
      "Result: 0.6076666116714478\n",
      "Result: 0.6201937794685364\n",
      "Result: 0.6262627840042114\n",
      "Result: 0.6402022838592529\n",
      "Result: 0.639018714427948\n",
      "Result: 0.6486251354217529\n",
      "Result: 0.653997540473938\n",
      "Result: 0.658271074295044\n",
      "Result: 0.6563290953636169\n",
      "Result: 0.6603070497512817\n",
      "Result: 0.670653760433197\n",
      "Result: 0.6752229332923889\n",
      "Result: 0.6762444376945496\n",
      "Result: 0.6807129979133606\n",
      "Result: 0.6826766133308411\n",
      "Result: 0.681998610496521\n",
      "Result: 0.6827696561813354\n",
      "Result: 0.6723955273628235\n",
      "Result: 0.6705402731895447\n",
      "Result: 0.6678792238235474\n",
      "Result: 0.6644889116287231\n",
      "Result: 0.6636974811553955\n",
      "Result: 0.6610156297683716\n",
      "Result: 0.6540312767028809\n",
      "Result: 0.656657338142395\n",
      "Result: 0.6486347913742065\n",
      "Result: 0.6438012719154358\n",
      "Result: 0.6473541259765625\n",
      "Result: 0.645044207572937\n",
      "Result: 0.6467985510826111\n",
      "Result: 0.63447505235672\n",
      "Result: 0.6237745881080627\n",
      "Result: 0.604150652885437\n",
      "Result: 0.5946191549301147\n",
      "Result: 0.5986509919166565\n",
      "Result: 0.5876579284667969\n",
      "Result: 0.5767150521278381\n",
      "Result: 0.5518374443054199\n",
      "Result: 0.5220316648483276\n",
      "Result: 0.5276612043380737\n",
      "Result: 0.5302863121032715\n",
      "Result: 0.5210337042808533\n",
      "Result: 0.5101222991943359\n"
     ]
    }
   ],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils \n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "landmarks = [\"class\"]\n",
    "for val in range(1, 33+1):\n",
    "    landmarks += ['x{}'.format(val), 'y{}'.format(val), 'z{}'.format(val), 'v{}'.format(val)]\n",
    "\n",
    "vid_path = \"test.mp4\"\n",
    "cap = cv2.VideoCapture(vid_path)\n",
    "current_stage = ''\n",
    "\n",
    "# Initiate Pose Model\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    # Streaming the video\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Resize the frame to the desired window size\n",
    "        frame = cv2.resize(frame, (720, 600))\n",
    "\n",
    "        # Recolor feed\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "\n",
    "        # Make detections\n",
    "        results = pose.process(image)\n",
    "\n",
    "        # Recolor image back to BGR for rendering\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                  mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=4),\n",
    "                                  mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2))\n",
    "        try:\n",
    "            if results.pose_landmarks:\n",
    "                row = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten().tolist()\n",
    "                row = np.expand_dims(row, axis=0)  # Add a batch dimension\n",
    "                prediction = model.predict(row)\n",
    "                print(f'Result: {prediction[0][0]}')\n",
    "                \n",
    "                if prediction[0][0] > 0.5:\n",
    "                    current_stage = 'Correct'\n",
    "                elif prediction[0][0] <= 0.5:\n",
    "                    current_stage = 'Wrong'\n",
    "\n",
    "                cv2.rectangle(image, (0, 0), (250, 60), (245, 117, 16), -1)\n",
    "\n",
    "                cv2.putText(image, 'CLASS', (95, 12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "                cv2.putText(image, current_stage, (95, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "                cv2.putText(image, 'PROB', (15, 12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "                cv2.putText(image, str(round(prediction[0][0], 2)), (10, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "\n",
    "\n",
    "        # Stream video result\n",
    "        cv2.imshow(\"Raw Cam Feed\", image)\n",
    "\n",
    "        # Press 'q' to stop the video\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
